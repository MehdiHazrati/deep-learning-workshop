{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Deep Learning in Computer Vision</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n",
      "Testing data shape :  (10000, 28, 28) (10000,)\n",
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "print('Training data shape : ', train_images.shape, train_labels.shape)\n",
    "print('Testing data shape : ', test_images.shape, test_labels.shape)\n",
    " \n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_labels)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    " \n",
    "plt.figure(figsize=[10,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 7')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_images[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_labels[0]))\n",
    " \n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_images[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Change from matrix to array of dimension 28x28 to array of dimention 784\n",
    "dimData = np.prod(train_images.shape[1:])\n",
    "train_data = train_images.reshape(train_images.shape[0], dimData)\n",
    "test_data = test_images.reshape(test_images.shape[0], dimData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Change to float datatype\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    " \n",
    "# Scale the data to lie between 0 to 1\n",
    "train_data /= 255\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label 0 :  5\n",
      "After conversion to categorical ( one-hot ) :  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label 0 : ', train_labels[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Create a Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.2722 - accuracy: 0.9148 - val_loss: 0.1333 - val_accuracy: 0.9582\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0940 - accuracy: 0.9704 - val_loss: 0.1045 - val_accuracy: 0.9679\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0590 - accuracy: 0.9812 - val_loss: 0.0744 - val_accuracy: 0.9766\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.0721 - val_accuracy: 0.9795\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0607 - val_accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_labels_one_hot, batch_size=256, epochs=5, verbose=1, \n",
    "                   validation_data=(test_data, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9828\n",
      "Evaluation result on Test Data : Loss = 0.06066329404711723, accuracy = 0.9828000068664551\n"
     ]
    }
   ],
   "source": [
    "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Get Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.7031891e-10, 3.8479985e-07, 1.3093343e-07, 7.6028726e-07,\n",
       "        4.0316871e-11, 1.3976782e-08, 3.8490915e-13, 9.9999869e-01,\n",
       "        1.4053629e-09, 9.0137895e-08]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data[[0],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Curves')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[//]: <> (REF: https://www.learnopencv.com/wp-content/uploads/2017/10/loss-curve-without-reg.png)\n",
    "[//]: <> (REF: https://www.learnopencv.com/wp-content/uploads/2017/10/acc-curve-without-reg.png)\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td> <img src=\"elements/images/applications/loss-curve-without-reg.png\" alt=\"RE\" align=\"middle\" style=\"width: 400px;\"/></td>\n",
    "<td> <img src=\"elements/images/applications/acc-curve-without-reg.png\" alt=\"RE\" align=\"middle\" style=\"width: 400px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The validation loss is increasing\n",
    "* The difference between the train and validation accuracy is very high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://www.learnopencv.com/wp-content/uploads/2017/10/loss-curve-with-reg.png)\n",
    "[//]: <> (REF: https://www.learnopencv.com/wp-content/uploads/2017/10/acc-curve-with-reg.png)\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td> <img src=\"elements/images/applications/loss-curve-with-reg.png\" alt=\"RE\" align=\"middle\" style=\"width: 400px;\"/></td>\n",
    "<td> <img src=\"elements/images/applications/acc-curve-with-reg.png\" alt=\"RE\" align=\"middle\" style=\"width: 400px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: http://everglory99.github.io/Intro_DL_TCC/intro_dl_images/dropout1.png)\n",
    "<img src=\"elements/images/applications/dropout1.png\" alt=\"DR\" align=\"middle\" style=\"width: 1100px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "keras.layers.Dropout(rate, noise_shape=None, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "More: http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Lp-Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://www.researchgate.net/profile/Younghak_Shin2/publication/230633149/figure/fig7/AS:300644943581190@1448690748255/Figure-9-L1-and-L2-norm-minimization.png)\n",
    "<img src=\"elements/images/applications/Figure-9-L1-and-L2-norm-minimization.png\" alt=\"LPNORM\" align=\"middle\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://www.youtube.com/watch?v=sO4ZirJh9ds)\n",
    "<img src=\"elements/images/applications/regu.png\" alt=\"LPNORM\" align=\"middle\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* kernel_regularizer: Regularizer function applied to the kernel weights matrix\n",
    "* bias_regularizer: Regularizer function applied to the bias vector\n",
    "* activity_regularizer: Regularizer function applied to the output of the layer (its \"activation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* keras.regularizers.l1(0.)\n",
    "* keras.regularizers.l2(0.)\n",
    "* keras.regularizers.l1_l2(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concepts and Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://i.stack.imgur.com/SFST9.gif)\n",
    "[//]: <> (REF: https://cdn-images-1.medium.com/max/1600/1*1VJDP6qDY9-ExTuQVEOlVg.gif)\n",
    "<table align=\"center\">\n",
    "<tr>\n",
    "<td> <img src=\"elements/images/applications/SFST9.gif\" alt=\"CONV\" align=\"middle\" style=\"width: 400px;\"/> </td>\n",
    "<td> <img src=\"elements/images/applications/conv.gif\" alt=\"CONV\" align=\"middle\" style=\"width: 300px;\"/> </td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Auto-Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://siavashk.github.io/assets/ae1.jpg)\n",
    "<img src=\"elements/images/applications/ae1.jpg\" alt=\"AE\" align=\"middle\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<h5>Why AutoEncoders?</h5>\n",
    "    1. Many Algorithms works well only in Low Dimensional Cases\n",
    "    2. Huge efforts need to provide annotated examples\n",
    "    3. AutoEncoders are great for reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://cdn-images-1.medium.com/max/1600/1*8ixTe1VHLsmKB3AquWdxpQ.png)\n",
    "<img src=\"elements/images/applications/1-8ixTe1VHLsmKB3AquWdxpQ.png\" alt=\"AE\" align=\"middle\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Autoencoders:\n",
    "* Undercomplete AutoEncoder\n",
    "* Regularized AutoEncoder\n",
    "* Sparse AutoEncoder\n",
    "* Denosoising AutoEncoder\n",
    "* Variational AutoEncoder\n",
    "* Seq2Seq AutoEncoder\n",
    "* etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://deeplearning4j.org/img/deep_autoencoder.png)\n",
    "<img src=\"elements/images/applications/deep_autoencoder.png\" alt=\"AE\" align=\"middle\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can find more detail about implementation of autoencoders here:\n",
    "    * https://github.com/mvpcom/ShirazuDL/blob/master/July%202017/01_KerasExample_FirstDay.ipynb\n",
    "    * https://github.com/mvpcom/ShirazuDL/blob/master/July%202017/02_KerasExamples_SecondDay.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Skip Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://image.slidesharecdn.com/dlsl2017d2l6advanceddeeparchitectures-170125171011/95/advanced-deep-architectures-d2l6-deep-learning-for-speech-and-language-upc-2017-17-638.jpg?cb=1485364567)\n",
    "<img src=\"elements/images/applications/advanced-deep-architectures.jpg\" alt=\"SK\" align=\"middle\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Residual Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://mblogthumb-phinf.pstatic.net/MjAxNzA0MjZfMTAg/MDAxNDkzMTc2MTk5MjY3.ZNrpsJ6UlcgaaZHR5QlLlZK0vp8Azuoyu84aH1hqD4wg.ZAJlUZiwje3HIuB1mxFnh9t5no1NcIg1_pXLIC4RWxcg.PNG.kangdonghyun/image.png?type=w800)\n",
    "<img src=\"elements/images/applications/residualBlock.png\" alt=\"RB\" align=\"middle\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Input\n",
    "\n",
    "# input tensor for a 3-channel 256x256 image\n",
    "x = Input(shape=(256, 256, 3))\n",
    "# 3x3 conv with 3 output channels (same as input channels)\n",
    "y = Conv2D(3, (3, 3), padding='same')(x)\n",
    "# this returns x + y.\n",
    "z = keras.layers.add([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 3)  84          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256, 256, 3)  0           ['input_1[0][0]',                \n",
      "                                                                  'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84\n",
      "Trainable params: 84\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "Model(inputs=x,outputs=z).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transposed Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: http://deeplearning.net/software/theano/_images/no_padding_no_strides_transposed.gif)\n",
    "<img src=\"elements/images/applications/no_padding_no_strides_transposed.gif\" alt=\"RB\" align=\"middle\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "keras.layers.Conv2DTranspose(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dilated Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: http://deeplearning.net/software/theano/_images/dilation.gif)\n",
    "<img src=\"elements/images/applications/dilation.gif\" alt=\"RB\" align=\"middle\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Inception Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://i.ytimg.com/vi/VxhSouuSZDY/maxresdefault.jpg)\n",
    "<img src=\"elements/images/applications/maxresdefault.jpg\" alt=\"AE\" align=\"middle\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fully Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: http://www.cvc.uab.es/people/joans/slides_tensorflow/tensorflow_html/layers_files/segnet.png)\n",
    "<img src=\"elements/images/applications/segnet.png\" alt=\"AE\" align=\"middle\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: http://rnd.azoft.com/wp-content/uploads_rnd/2016/11/overall-1024x256.png)\n",
    "<img src=\"elements/images/applications/overall-1024x256.png\" alt=\"AE\" align=\"middle\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fine-Tuning and Frozen Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trainable=False\n",
    "frozen_layer = Dense(32, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(32,))\n",
    "layer = Dense(32)\n",
    "layer.trainable = False\n",
    "y = layer(x)\n",
    "\n",
    "frozen_model = Model(x, y)\n",
    "# in the model below, the weights of `layer` will not be updated during training\n",
    "frozen_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "layer.trainable = True\n",
    "trainable_model = Model(x, y)\n",
    "# with this model the weights of the layer will be updated during training\n",
    "# (which will also affect the above model since it uses the same layer instance)\n",
    "trainable_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# frozen_model.fit(train_data, train_labels)  # this does NOT update the weights of `layer`\n",
    "# trainable_model.fit(train_data, train_labels)  # this updates the weights of `layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Image Augmentation and Data Providing "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Popular State-of-The-Art Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### VGG16/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://www.pyimagesearch.com/wp-content/uploads/2017/03/imagenet_vgg16.png)\n",
    "<img src=\"elements/images/applications/imagenet_vgg16.png\" alt=\"VGG\" align=\"middle\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "#model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Microsoft ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: http://book.paddlepaddle.org/03.image_classification/image/resnet.png)\n",
    "<img src=\"elements/images/applications/resnet.png\" alt=\"ResNet\" align=\"middle\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Yolo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://chaosmail.github.io/images/deep-learning/localizationVsDetection.png)\n",
    "<img src=\"elements/images/applications/localizationVsDetection.png\" alt=\"OB\" align=\"middle\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://pjreddie.com/media/image/model2.png)\n",
    "<img src=\"elements/images/applications/model2.png\" alt=\"YOLO\" align=\"middle\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://github.com/xslittlegrass/CarND-Vehicle-Detection/blob/master/output_images/mode_yolo_plot.jpg)\n",
    "<img src=\"elements/images/applications/mode_yolo_plot.jpg\" alt=\"YOLO\" align=\"middle\" style=\"width: 1200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[//]: <> (REF: https://github.com/xslittlegrass/CarND-Vehicle-Detection/blob/master/output_images/net_output.png)\n",
    "<img src=\"elements/images/applications/net_output.png\" alt=\"YOLO\" align=\"middle\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " * Image Classification *\n",
    " * Image Segmentation *\n",
    " * Object Detection\n",
    " * Image Generation\n",
    " * Scene Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Traffic Light Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, MaxPooling2D, Convolution2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3\n",
    "IMAGE_WIDTH = 224 \n",
    "IMAGE_HEIGHT = 224 \n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# keras image generator\n",
    "def get_generator(directory, train):\n",
    "    if train:\n",
    "        datagen = ImageDataGenerator(\n",
    "          rescale=1./255,\n",
    "          shear_range=0.2,\n",
    "          zoom_range=0.2,\n",
    "          horizontal_flip=True)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    return datagen.flow_from_directory(\n",
    "        directory=directory,\n",
    "        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        batch_size=8,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotSpecialTool(data,labels,samples2Visualize=12,factors=[2,6], figsize=(20,12), grayFlag=False, thr=0.0):\n",
    "    # samples2Visualize = 12 # sample 12 random number\n",
    "    # factors = [2,6] # indicate two factors for number of samples\n",
    "    assert np.prod(np.array(factors))==samples2Visualize, \"%rx%r is not equal to %r\" % (factors[0],factors[1],samples2Visualize)\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    nLimit = data.shape[0]\n",
    "    for i in range(1,samples2Visualize+1):\n",
    "        img = figure.add_subplot(factors[0],factors[1],i)\n",
    "        # randomly sample an image from train set\n",
    "        imgID = np.random.randint(nLimit-1)\n",
    "        image = data[imgID]\n",
    "        #image = image[60:150,:]\n",
    "        if grayFlag:\n",
    "            plt.imshow(image.reshape(image.shape[0],image.shape[1]), cmap=plt.get_cmap('gray'))\n",
    "        else:\n",
    "            plt.imshow(image)\n",
    "        img.set_title(labels[imgID],fontsize=7)\n",
    "        plt.axis('off')\n",
    "#plotSpecialTool(centerImgs,labelsCSV[\"label\"],factors=[3,4],thr=0.0,grayFlag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load images\n",
    "# import cv2\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "def loadImg(imgLoc):\n",
    "    imageLocation = imgLoc\n",
    "    image = misc.imread(imageLocation) #cv2.imread(imageLocation) # BGR\n",
    "    #b,g,r = cv2.split(image)       # get b,g,r\n",
    "    #image = cv2.merge([r,g,b])     # switch it to rgb\n",
    "\n",
    "    if (image is None):\n",
    "        print(imageLocation)\n",
    "     \n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "#numSample = 12\n",
    "#centerImgs = np.array([loadImg(imgLoc) for imgLoc in labelsCSV['filename'][0:numSample]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3922 images belonging to 2 classes.\n",
      "Found 110 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "directory = './Dataset/'\n",
    "train_generator = get_generator(directory+'train', True)\n",
    "validation_generator = get_generator(directory+'val', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 112, 112, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 37, 37, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 37, 37, 16)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 37, 37, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               295040    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 318,882\n",
      "Trainable params: 318,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  Convolution2D(16, (3, 3), padding='same', strides=(2, 2), input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS), activation='relu'),\n",
    "  MaxPooling2D(pool_size=(3, 3)),\n",
    "  Dropout(0.2),\n",
    "\n",
    "  Convolution2D(32, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(3, 3)),\n",
    "  Dropout(0.2),\n",
    "\n",
    "  Convolution2D(64, (3, 3), padding='same', activation='relu'),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Dropout(0.2),\n",
    "\n",
    "  Flatten(),\n",
    "  Dense(128, activation='tanh'),\n",
    "  Dropout(0.5), # 0.3 works fine\n",
    "  Dense(NUM_CLASSES, activation='softmax'),\n",
    "])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
